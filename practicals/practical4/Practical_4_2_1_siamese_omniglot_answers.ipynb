{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on: https://sorenbouma.github.io/blog/oneshot/ and https://github.com/sorenbouma/keras-oneshot/blob/master/SiameseNet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network architecture\n",
    "We define a Siamese Network for use with the Omniglot dataset. The architecture is similar to that in the paper (Koch et al., \"Siamese Neural Networks for One-shot Image Recognition\"), but we include dropout and batch normalization to improve generalization and speed up training.\n",
    "\n",
    "Each siamese \"leg\" is a convnet that transforms data to a 4096-dimensional representation. The metric we are trying to learn is the L1-distance between such representations. The output of the full Siamese Network represents the probability that the two input images are \"similar\" (in this case: of the same class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 64)        6464      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9216)              36864     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              37752832  \n",
      "=================================================================\n",
      "Total params: 38,985,792\n",
      "Trainable params: 38,966,720\n",
      "Non-trainable params: 19,072\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         38985792    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,989,889\n",
      "Trainable params: 38,970,817\n",
      "Non-trainable params: 19,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "# build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Conv2D(128, (7,7), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Conv2D(128, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Conv2D(256, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Dense(4096, activation=\"sigmoid\", kernel_regularizer=l2(1e-3)))\n",
    "convnet.summary()\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "# merge two encoded inputs with the L1 distance between them, and connect to prediction output layer\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = Lambda(L1_distance)([encoded_l, encoded_r])\n",
    "prediction = Dense(1, activation='sigmoid')(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
    "\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniglot Data\n",
    "We pickled the Omniglot dataset with the \"Practical-4.2.0_preprocess-omniglot.ipynb\" notebook, as an array of shape (n_classes x n_examples x width x height), and there is an accompanying dictionary to specify which indexes belong to which languages. Let's load this data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (964, 20, 105, 105)\n",
      "X_test shape: (659, 20, 105, 105)\n",
      "\n",
      "training alphabets\n",
      "['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)', 'Balinese', 'Bengali', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Braille', 'Burmese_(Myanmar)', 'Cyrillic', 'Early_Aramaic', 'Futurama', 'Grantha', 'Greek', 'Gujarati', 'Hebrew', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Japanese_(hiragana)', 'Japanese_(katakana)', 'Korean', 'Latin', 'Malay_(Jawi_-_Arabic)', 'Mkhedruli_(Georgian)', 'N_Ko', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Sanskrit', 'Syriac_(Estrangelo)', 'Tagalog', 'Tifinagh']\n",
      "test alphabets:\n",
      "['Angelic', 'Atemayar_Qelisayer', 'Atlantean', 'Aurek-Besh', 'Avesta', 'Ge_ez', 'Glagolitic', 'Gurmukhi', 'Kannada', 'Keble', 'Malayalam', 'Manipuri', 'Mongolian', 'Old_Church_Slavonic_(Cyrillic)', 'Oriya', 'Sylheti', 'Syriac_(Serto)', 'Tengwar', 'Tibetan', 'ULOG']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Alphabet_of_the_Magi': [0, 19],\n",
       " 'Anglo-Saxon_Futhorc': [20, 48],\n",
       " 'Arcadian': [49, 74],\n",
       " 'Armenian': [75, 115],\n",
       " 'Asomtavruli_(Georgian)': [116, 155],\n",
       " 'Balinese': [156, 179],\n",
       " 'Bengali': [180, 225],\n",
       " 'Blackfoot_(Canadian_Aboriginal_Syllabics)': [226, 239],\n",
       " 'Braille': [240, 265],\n",
       " 'Burmese_(Myanmar)': [266, 299],\n",
       " 'Cyrillic': [300, 332],\n",
       " 'Early_Aramaic': [333, 354],\n",
       " 'Futurama': [355, 380],\n",
       " 'Grantha': [381, 423],\n",
       " 'Greek': [424, 447],\n",
       " 'Gujarati': [448, 495],\n",
       " 'Hebrew': [496, 517],\n",
       " 'Inuktitut_(Canadian_Aboriginal_Syllabics)': [518, 533],\n",
       " 'Japanese_(hiragana)': [534, 585],\n",
       " 'Japanese_(katakana)': [586, 632],\n",
       " 'Korean': [633, 672],\n",
       " 'Latin': [673, 698],\n",
       " 'Malay_(Jawi_-_Arabic)': [699, 738],\n",
       " 'Mkhedruli_(Georgian)': [739, 779],\n",
       " 'N_Ko': [780, 812],\n",
       " 'Ojibwe_(Canadian_Aboriginal_Syllabics)': [813, 826],\n",
       " 'Sanskrit': [827, 868],\n",
       " 'Syriac_(Estrangelo)': [869, 891],\n",
       " 'Tagalog': [892, 908],\n",
       " 'Tifinagh': [909, 963]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.path.join(\"data\", \"omniglot\")\n",
    "\n",
    "with open(os.path.join(PATH, \"omniglot_train.p\"), \"rb\") as f:\n",
    "    (X_train, c_train) = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(PATH, \"omniglot_test.p\"), \"rb\") as f:\n",
    "    (X_test, c_test) = pickle.load(f)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"\")\n",
    "print(\"training alphabets\")\n",
    "print([key for key in c_train.keys()])\n",
    "print(\"test alphabets:\")\n",
    "print([key for key in c_test.keys()])\n",
    "\n",
    "c_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training set contains 964 different characters, each belonging to one of 30 languages/scripts. The test set contains 659 different characters, each belonging to one of 20 languages/scripts. Each class (character) has only 20 examples, thus training a classifier on them would likely severely overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions\n",
    "To be able to train the Siamese Network we need to do a bit more work than for a simple classification network. We cannot simply feed the full dataset into the network batch by batch, instead here we need pairs of examples. These should be positive examples (where both images are from the same class, with a target output of 1) and negative examples (where the two input images are from a different class, with a target output of 0).\n",
    "\n",
    "To achieve this, we define the \"get_batch\" function which selects a number of pairs, half of them with images from the same class, and half of them with images from two different classes.\n",
    "\n",
    "We also define a generator function \"batch_generator\" that will repeatedly generate batches using \"get_batch\", such that we can use it for training with Keras's \"fit_generator\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs = [np.zeros((batch_size, h, w, 1)) for i in range(2)]\n",
    "    # initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "    targets = np.zeros((batch_size,))\n",
    "    targets[batch_size//2:] = 1\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = np.random.randint(0, n_examples)\n",
    "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, 1)\n",
    "        idx_2 = np.random.randint(0, n_examples)\n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        if i >= batch_size // 2:\n",
    "            category_2 = category\n",
    "        else:\n",
    "            #add a random number to the category modulo n_classes to ensure 2nd image has different category\n",
    "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h, 1)\n",
    "    return pairs, targets\n",
    "\n",
    "def batch_generator(batch_size, X):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size, X)\n",
    "        yield (pairs, targets)\n",
    "\n",
    "def train(model, X_train, batch_size=64, steps_per_epoch=100, epochs=1):\n",
    "    model.fit_generator(batch_generator(batch_size, X_train), steps_per_epoch=steps_per_epoch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot functions\n",
    "The paper aims at using Siamese Networks for N-way One-shot Image Recognition. In this scenario, N examples of reference images are given, each belonging to a different class, as well as a test image that corresponds to exactly one of these classes. The task is to correctly classify which class the test image belongs to, given only one example from each of the N classes.\n",
    "\n",
    "We define a function \"make_oneshot_task\" that can randomly setup such a one-shot task from a given test set (if a language is specified, using only classes/characters from that language), i.e. it will generate N pairs of images, where the first image is always the test image, and the second image is one of the N reference images. The pair of images from the same class will have target 1, all other targets are 0.\n",
    "\n",
    "The function \"test_oneshot\" will generate a number (k) of such one-shot tasks and evaluate the performance of a given model on these tasks; it reports the percentage of correctly classified test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_oneshot_task(N, X, c, language=None):\n",
    "    \"\"\"Create pairs of (test image, support set image) with ground truth, for testing N-way one-shot learning.\"\"\"\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    indices = np.random.randint(0, n_examples, size=(N,))\n",
    "    if language is not None:\n",
    "        low, high = c[language]\n",
    "        if N > high - low:\n",
    "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "        categories = np.random.choice(range(low,high), size=(N,), replace=False)\n",
    "    else:  # if no language specified just pick a bunch of random letters\n",
    "        categories = np.random.choice(range(n_classes), size=(N,), replace=False)            \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
    "    test_image = np.asarray([X[true_category, ex1, :, :]]*N).reshape(N, w, h, 1)\n",
    "    support_set = X[categories, indices, :, :]\n",
    "    support_set[0, :, :] = X[true_category, ex2]\n",
    "    support_set = support_set.reshape(N, w, h, 1)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image, support_set]\n",
    "    return pairs, targets\n",
    "\n",
    "def test_oneshot(model, X, c, N=20, k=250, language=None, verbose=True):\n",
    "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N, X, c, language=language)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct += 1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting example one-shot tasks\n",
    "Let's visualize some one-shot tasks to get an idea of how well humans can solve such tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc,h,w,_ = X.shape\n",
    "    X = X.reshape(nc,h,w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "def plot_oneshot_task(pairs):\n",
    "    \"\"\"Takes a one-shot task given to a siamese net and  \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f7a99cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs, targets = make_oneshot_task(20, X_train, c_train, language=\"Japanese_(katakana)\")\n",
    "plot_oneshot_task(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh4LBoWBwKBgcCgaHgsGhYHAoGJz/AKel4mcJx0QyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f7a9dfa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs, targets = make_oneshot_task(20, X_train, c_train)\n",
    "plot_oneshot_task(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Let's train the model now. In each training loop, we sample 100 batches of 64 image pairs (as specified in the \"train\" method above), after which we evaluate the one-shot image recognition accuracy of the model. Whenever the model achieves a new best accuracy, we save its weights to a file (note that we do not directly use the value of the loss function).\n",
    "\n",
    "*NOTE: training may take a long time, especially if training on CPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training loop 1 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 76s 764ms/step - loss: 5.6446\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 2 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 68s 685ms/step - loss: 1.7219\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 29.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 3 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 1.3847\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 31.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 4 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 1.3284\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 31.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 5 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 690ms/step - loss: 1.3214\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 34.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 6 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 1.3710\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 7 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.3245\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 46.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 8 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.3661\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 28.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 9 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.3672\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 41.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 10 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 1.3551\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 47.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 11 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.3741\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 45.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 12 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.3700\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 36.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 13 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.4105\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 48.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 14 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.3836\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 41.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 15 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.4000\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 45.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 16 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 1.4187\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 46.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 17 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.3500\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 44.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 18 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.3619\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 42.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 19 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.4194\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 49.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 20 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 1.3511\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 45.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 21 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 1.3002\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 33.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 22 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 1.3251\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 44.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 23 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.3485\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 50.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 24 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.3402\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 43.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 25 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.3002\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 48.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 26 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.3090\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 45.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 27 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 1.2761\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 38.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 28 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 1.3153\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 38.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 29 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.2595\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 46.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 30 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 1.2322\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 44.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 31 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 1.2415\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 46.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 32 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 1.2152\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 52.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 33 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.1772\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 53.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 34 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 1.1600\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 59.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 35 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 1.1737\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 44.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 36 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 1.1626\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 50.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 37 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 1.1191\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 54.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 38 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.0901\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 40.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 39 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 693ms/step - loss: 1.0456\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 60.4% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 40 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 1.1240\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 51.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 41 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 1.0981\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 61.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 42 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 1.0683\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 56.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 43 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 1.1005\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 58.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 44 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 1.0832\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 30.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 45 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.0336\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 53.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 46 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 1.0020\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 51.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 47 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.9974\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 59.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 48 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 0.9990\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 59.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 49 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 1.0282\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 65.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 50 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.9785\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 50.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 51 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.9955\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 58.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 52 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.9619\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 62.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 53 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.9163\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 63.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 54 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.9251\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 64.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 55 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.9160\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 61.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 56 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.8776\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 65.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 57 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8697\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 64.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 58 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.8087\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 62.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 59 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.7830\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 57.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 60 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 695ms/step - loss: 0.7481\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 59.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 61 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.8061\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 57.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 62 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.8255\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 66.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 63 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.7954\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 67.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 64 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 711ms/step - loss: 0.8331\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 62.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 65 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7861\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 68.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 66 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7449\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 55.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 67 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7220\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 53.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 68 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7643\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 65.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 69 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.7664\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 64.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 70 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.7494\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 63.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 71 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7306\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 63.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 72 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7233\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 69.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 73 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7021\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 68.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 74 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7037\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 58.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 75 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.7397\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 66.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 76 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.7412\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 52.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 77 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7440\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 59.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 78 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.7062\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 66.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 79 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 0.6999\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 71.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 80 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.6621\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 73.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 81 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.6770\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 68.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 82 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.7096\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 67.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 83 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.6731\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 59.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 84 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.6618\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 68.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 85 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.6290\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 65.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 86 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.6332\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 63.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 87 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.6189\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 72.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 88 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.6247\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.4% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 89 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.5761\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 47.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 90 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.5991\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 68.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 91 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.6161\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 72.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 92 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.6098\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 93 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.5823\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 42.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 94 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.5828\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 53.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 95 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 712ms/step - loss: 0.6263\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 50.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 96 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.6246\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 66.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 97 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.6190\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 55.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 98 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 0.6197\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 72.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 99 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.6063\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 69.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 100 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.6253\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 70.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 101 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.6395\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 33.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 102 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.6163\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 61.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 103 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.5805\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 35.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 104 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.5680\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 45.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 105 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.5569\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 60.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 106 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.5546\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 74.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 107 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.5468\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 66.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 108 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.5505\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 37.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 109 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.5735\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 68.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 110 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.5784\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 75.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 111 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.5371\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 72.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 112 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.5341\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 73.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 113 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.5491\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 114 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.5270\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.0% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 115 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.5172\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 77.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 116 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.5163\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 64.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 117 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.5156\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 67.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 118 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 0.5162\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 49.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 119 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.5249\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 74.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 120 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.5012\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 121 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.4942\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 62.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 122 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.5275\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 77.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 123 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.5184\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 71.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 124 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 0.4938\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 74.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 125 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.5231\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 126 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.4995\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 70.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 127 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.5165\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 66.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 128 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.5163\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 75.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 129 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.5052\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 130 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.4993\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 131 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.4873\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 132 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.4878\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 133 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.4861\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 71.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 134 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 695ms/step - loss: 0.4775\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 31.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 135 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.4684\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 136 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 0.4408\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.8% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 137 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.4262\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 138 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.4457\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 49.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 139 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.4652\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 75.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 140 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.4399\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 83.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 141 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.4223\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 142 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.4484\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 143 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.4306\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 81.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 144 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.4267\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 145 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.4168\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 62.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 146 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.4023\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 147 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.4075\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 148 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.3997\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 149 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.4302\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 150 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.4270\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 83.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 151 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.4126\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 152 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.3860\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 153 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 689ms/step - loss: 0.4111\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 83.6% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 154 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 695ms/step - loss: 0.4181\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 75.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 155 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.4179\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 81.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 156 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 695ms/step - loss: 0.4293\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 84.4% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 157 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 695ms/step - loss: 0.4184\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 158 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 695ms/step - loss: 0.4098\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 81.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 159 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.4136\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 160 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 695ms/step - loss: 0.3962\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 161 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.3877\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 87.2% accuracy for 20-way one-shot learning\n",
      "New best one-shot accuracy, saving model ...\n",
      "=== Training loop 162 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 693ms/step - loss: 0.3923\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 83.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 163 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.3794\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 83.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 164 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.3953\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 83.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 165 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.3957\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 72.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 166 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 0.3757\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 84.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 167 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.3701\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 67.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 168 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.4088\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 169 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.4056\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 170 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.3955\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 171 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.3787\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 172 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.3800\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 84.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 173 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 0.3691\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 174 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.3597\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 81.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 175 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.3690\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 176 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 696ms/step - loss: 0.3859\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 63.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 177 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 690ms/step - loss: 0.3808\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 178 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.3811\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 179 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.3625\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 86.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 180 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.3733\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 181 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.3869\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 84.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 182 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.3713\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 76.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 183 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.3677\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 184 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.3642\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 81.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 185 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.3597\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 64.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 186 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.3551\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 78.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 187 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 689ms/step - loss: 0.3482\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 84.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 188 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.3616\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 189 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.3570\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 82.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 190 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.3406\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 79.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 191 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.3636\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 192 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.3567\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 193 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 0.3467\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 86.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 194 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.3478\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 81.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 195 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.3327\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 80.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 196 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 693ms/step - loss: 0.3270\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 86.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 197 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.3266\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 72.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 198 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.3410\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 74.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 199 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 689ms/step - loss: 0.3518\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 84.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 200 ===\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.3518\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 71.6% accuracy for 20-way one-shot learning\n"
     ]
    }
   ],
   "source": [
    "loops = 200\n",
    "best_acc = 0\n",
    "for i in range(loops):\n",
    "    print(\"=== Training loop {} ===\".format(i+1))\n",
    "    train(siamese_net, X_train)\n",
    "    test_acc = test_oneshot(siamese_net, X_test, c_test)\n",
    "    if test_acc >= best_acc:\n",
    "        print(\"New best one-shot accuracy, saving model ...\")\n",
    "        siamese_net.save(os.path.join(\"models\", \"siamese_omniglot.h5\"))\n",
    "        best_acc = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
